{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_Algebra_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTtqFdWyIGPfpdfxQ7IIFH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WereszczynskiClasses/Phys240_Solutions/blob/main/Activity_Linear_Algebra_2_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPpEdfWuIXGL"
      },
      "source": [
        "# Other matrix operations\n",
        "\n",
        "Most matrix operations work as you'd expect in python.  For example, additions adds each of the elements of two matrices together and subtraction subtracts them.  There are a couple of important difference though which we'll note here, and some additional operations you should be aware of."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FgkP_SqIpce"
      },
      "source": [
        "## Matrix multiplication\n",
        "\n",
        "Be careful with matrix multiplication in python.  By default, if you use the ```*``` operation on two matrices you'll multiply each element of two arrays together, which is not what you want.  The solution is simple: use the ```@``` operator to multiply two matrices\n",
        "\n",
        "**Activity** Define two matrices.  Matrix **A** should be a $3x4$ matrix and matrix **B** should be a $4x3$.  Try multiplying them together using the ```*``` operator and note the error that you get (it’s important to see these errors so that you know what they mean when you encounter them in coding).  Then try multiplying them using the ```@``` operator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN0YknLFIWA9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "ad6186e6-8744-4af6-cbc5-34ced47d1ca8"
      },
      "source": [
        "import numpy as np\n",
        "B=np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
        "A=np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
        "print(\"A=\\n\",A)\n",
        "print(\"B=\\n\",B)\n",
        "A*B"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A=\n",
            " [[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]]\n",
            "B=\n",
            " [[ 1  2  3]\n",
            " [ 4  5  6]\n",
            " [ 7  8  9]\n",
            " [10 11 12]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-54ef9281feaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A=\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B=\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,4) (4,3) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd99_YaPUZT6",
        "outputId": "241dbf95-66ec-4a12-b35a-acc7ddce1fe1"
      },
      "source": [
        "print(A@B)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 70  80  90]\n",
            " [158 184 210]\n",
            " [246 288 330]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bHXrAUUK2HG"
      },
      "source": [
        "## Determinant calculations\n",
        "\n",
        "The determinant of a matrix is a useful quantity for telling us if a square matrix is singular and invertible, and can be used to determine how well \"conditioned\" a matrix is (that is, how sensitive is the matrix in calculations such as in solving linear equations to small changes in the values).  To calculate it is straightforward.  In the scipy linalg package you can use the ```linalg.det``` function, such as:\n",
        "\n",
        "```\n",
        "from scipy import linalg\n",
        "\n",
        "linalg.det(A)\n",
        "```\n",
        "\n",
        "**Activity** Calculate the determinant of the matrix:\n",
        "\n",
        "$ \n",
        "\\mathbf{A} =\n",
        "\\begin{pmatrix}\n",
        "2 & 4 & 6 & 9\\\\\n",
        "4 & 8& 3 & 4 \\\\\n",
        "6 & 3 & 2 & 1 \\\\\n",
        "9 & 4 & 1 & 1  \\\\\n",
        "\\end{pmatrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8c3wU2dK1Rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958e00b6-456e-48f0-aa6f-bed017f6beaf"
      },
      "source": [
        "from scipy import linalg\n",
        "A= np.array([[2,4,6,9],[4,8,3,4],[6,3,2,1],[9,4,1,1]])\n",
        "print(\"A=\\n\",A)\n",
        "print(\"Determinant=\",linalg.det(A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A=\n",
            " [[2 4 6 9]\n",
            " [4 8 3 4]\n",
            " [6 3 2 1]\n",
            " [9 4 1 1]]\n",
            "Determinant= -433.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HOcxUV2Bxt1"
      },
      "source": [
        "## Matrix transpose\n",
        "\n",
        "The matrix transpose is simply flipping a matrix so that the rows become columns and the columns become rows.  This is easy to do in python.  If you have a matrix ```A```, you can compute the transpose of the matrix by either using the function:\n",
        "\n",
        "```np.transpose(A)```\n",
        "\n",
        "or the easier ways is to type:\n",
        "\n",
        "```A.T```\n",
        "\n",
        "Where the ```.T``` is for transpose.\n",
        "\n",
        "**Activity** Compute the transpose of the matrix:\n",
        "\n",
        "$\\begin{pmatrix}\n",
        "1 & 2 &3\\\\\n",
        "4 & 5 &6\n",
        "\\end{pmatrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X24uSdYUC90",
        "outputId": "daefd653-06f4-430f-96f1-2f01a7e8826a"
      },
      "source": [
        "A=np.array([[1,2,3],[4,5,6]])\n",
        "print(A.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 4]\n",
            " [2 5]\n",
            " [3 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl3jeKXUJHw6"
      },
      "source": [
        "## Identity Matrix\n",
        "\n",
        "The identity matrix is the matrix equivalent of the number 1.  It has ones on the diagonal and zeros everywhere else.  For example:\n",
        "\n",
        "$\n",
        "\\begin{pmatrix} \n",
        "1 & 0 & 0 & 0\\\\\n",
        "0 & 1 & 0 & 0 \\\\\n",
        "0 & 0 & 1& 0 \\\\\n",
        "0 & 0 & 0& 1\n",
        "\\end{pmatrix} \n",
        "$\n",
        "\n",
        "is the $4x4$ identity matrix.  This can be computed in python with the command:\n",
        "\n",
        "```np.eye(N)```\n",
        "\n",
        "where $N$ is the same of the desired identity matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gugzXuTaikoV"
      },
      "source": [
        " # QR Decomposition and Eigenvalues\n",
        "\n",
        "Last class we saw how we can decompose (or factor) a matrix into two other matrices using the \"LU decomposition,\" and how we can use those results to find solve systems of linear equations.  There are several other decomposition methods available, each of which have various uses.\n",
        "\n",
        "Another common decomposition algorithm is \"QR decomposition\".  In this method, a square matrix $\\mathbf{A}$ is factored into two matrices $\\mathbf{Q}$ and $\\mathbf{R}$:\n",
        "\n",
        "$\\mathbf{A}=\\mathbf{QR}$\n",
        "\n",
        "where $\\mathbf{Q}$  is an orthogonal matrix (that is, each column is a vector that is orthogonal to each of the other columns) and $\\mathbf{R}$ is an upper diagonal matrix (it's also called a right triangle matrix, hence why it is called $\\mathbf{R}$).  We won't go into the algorithms that have been developed to calculate this decomposition, but for those that are interested I would recommend looking into the Gram–Schmidt, Househoulder, or Givens processes.\n",
        "\n",
        "Of course, python has ways to compute the QR decomposition.  In SciPy, this is in the linalg module.  The function:\n",
        "\n",
        "```\n",
        "from scipy import linalg\n",
        "Q, R = linalg.qr(A)\n",
        "```\n",
        "\n",
        "Will return the matrices **Q** and **R** for the matrix **A**.  Note that because **Q** is an orthogonal matrix it has the nice property that:\n",
        "\n",
        "$\n",
        "\\mathbf{Q^T Q} = \\mathbf{I}$\n",
        "\n",
        "Where $\\mathbf{I}$ is the identity matrix (this is because the *ij*th element of the matrix $\\mathbf{Q^T Q}$ is the dot product of the $i$th and $j$th columns of $\\mathbf{I}$, so it will be 1 if i=j and 0 otherwise.\n",
        "\n",
        "**Activity**. Consider the matrix:\n",
        "\n",
        "$ \n",
        "\\mathbf{A} =\n",
        "\\begin{pmatrix}\n",
        "2 & 4 & 6 & 9\\\\\n",
        "4 & 8& 3 & 4 \\\\\n",
        "6 & 3 & 2 & 1 \\\\\n",
        "9 & 4 & 1 & 1  \\\\\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "Calculate the QR decomposition.  Use the results to show:\n",
        "\n",
        "1.  That the product of **Q** and **R** equals **A**.\n",
        "\n",
        "2.  That the product of $\\mathbf{Q}$ and $\\mathbf{Q^T}$ equals $I$.\n",
        "\n",
        "3.  That each of the columns of Q is orthogonal from each other column.  Note that you might find the numpy dot product function useful for this:\n",
        " \n",
        "  ```x = np.dot(a,b)```\n",
        "\n",
        "   which calculates the dot product of vectors $a$ and $b$ and stores it as $x$.\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVH6dq_58usL",
        "outputId": "c4f0d3f2-659f-40ce-a528-799f7aa44329"
      },
      "source": [
        "from scipy import linalg\n",
        "\n",
        "A= np.array([[2,4,6,9],[4,8,3,4],[6,3,2,1],[9,4,1,1]])\n",
        "\n",
        "Q,R=linalg.qr(A)\n",
        "print(\"A=\\n\",A)\n",
        "print(\"Q=\\n\",Q)\n",
        "print(\"R=\\n\",R)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A=\n",
            " [[2 4 6 9]\n",
            " [4 8 3 4]\n",
            " [6 3 2 1]\n",
            " [9 4 1 1]]\n",
            "Q=\n",
            " [[-0.17087153 -0.41289047  0.86769263  0.2177932 ]\n",
            " [-0.34174306 -0.82578093 -0.44392663 -0.0650129 ]\n",
            " [-0.51261459  0.17547845  0.18816589 -0.81916249]\n",
            " [-0.76892189  0.34178155 -0.12096379  0.52660446]]\n",
            "R=\n",
            " [[-11.70469991  -8.03096198  -3.84460946  -4.18635252]\n",
            " [  0.          -6.36424777  -4.26194714  -6.50187792]\n",
            " [  0.           0.           4.1297439    6.10072927]\n",
            " [  0.           0.           0.           1.4075292 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEvKb5gIaWrJ"
      },
      "source": [
        "Note that $\\mathbf{QR}=\\mathbf{A}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb7Du6Bb81gC",
        "outputId": "a78ca7b9-9144-4a77-8066-d9d438cb6518"
      },
      "source": [
        "print(Q@R)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2. 4. 6. 9.]\n",
            " [4. 8. 3. 4.]\n",
            " [6. 3. 2. 1.]\n",
            " [9. 4. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBqpG3Koad6J"
      },
      "source": [
        "Note that $\\mathbf{Q^T Q}=\\mathbf{I}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sezqSG7q80ua",
        "outputId": "6b5e9ca4-25f5-4e3d-b952-d0633a8910d5"
      },
      "source": [
        "print(Q.T@Q)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.00000000e+00  8.01794500e-17 -7.22161982e-17 -9.50519865e-17]\n",
            " [ 8.01794500e-17  1.00000000e+00  9.08893577e-18  6.78343248e-18]\n",
            " [-7.22161982e-17  9.08893577e-18  1.00000000e+00  1.12207981e-16]\n",
            " [-9.50519865e-17  6.78343248e-18  1.12207981e-16  1.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfnNkglXah5N"
      },
      "source": [
        "We can get the same result by computing all of the different pairs of dot products between the columns of $\\mathbf{Q}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZGxIxAKGZea",
        "outputId": "16bb268b-b369-4f06-bed2-f93a6daade3e"
      },
      "source": [
        "for i in range(4):\n",
        "  for j in range(i,4):\n",
        "    print(\"The dot product for column\",i,\"and\",j,\"is:\",np.dot(Q[:,i],Q[:,j]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dot product for column 0 and 0 is: 1.0000000000000002\n",
            "The dot product for column 0 and 1 is: 8.017945000873181e-17\n",
            "The dot product for column 0 and 2 is: -7.221619823054915e-17\n",
            "The dot product for column 0 and 3 is: -9.505198653113816e-17\n",
            "The dot product for column 1 and 1 is: 1.0000000000000002\n",
            "The dot product for column 1 and 2 is: 9.088935768406905e-18\n",
            "The dot product for column 1 and 3 is: 6.783432480966266e-18\n",
            "The dot product for column 2 and 2 is: 1.0\n",
            "The dot product for column 2 and 3 is: 1.1220798092731282e-16\n",
            "The dot product for column 3 and 3 is: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiK13oQ6Gv6y"
      },
      "source": [
        "One of the most useful applications of QR decomposition is for calculating eigenvectors and eigenvalues.  As a reminder, for a symmetric matrix $\\mathbf{A}$ an eigenvector $v$ is a vector which satisfies:\n",
        "\n",
        "$\\mathbf{Av} = \\lambda\\mathbf{v}$\n",
        "\n",
        " with $\\lambda$ the corresponding eigenvalue.  We can calculate all of the eigenvectors and eigenvalues using the matrix equation:\n",
        "\n",
        " $\\mathbf{AV} = \\mathbf{VD}$\n",
        "\n",
        " Where  $\\mathbf{V}$ is a matrix with each column corresponding to an eigenvector, and  $\\mathbf{D}$ is a diagonal matrix with each of the diagonal elements corresponding to an eigenvalue.  That is, if $A$ is a $4x4$matrix,  $\\mathbf{D}$ will look like:\n",
        "\n",
        " $\n",
        " \\begin{pmatrix}\n",
        " \\lambda_1 & 0 &0 &0 \\\\\n",
        " 0 &\\lambda_2 & 0 &0 \\\\\n",
        " 0& 0 &\\lambda_3 & 0  \\\\\n",
        " 0& 0 &0& \\lambda_4   \n",
        " \\end{pmatrix}\n",
        " $\n",
        "\n",
        " To find $\\mathbf{V}$, we take the following steps:\n",
        " \n",
        " 1. We perform a QR factorization of $\\mathbf{A}$:\n",
        "\n",
        "  $\\mathbf{A}=\\mathbf{Q_1 R_1}$\n",
        "\n",
        " we then use the fact that $\\mathbf{Q_1}$ is orthonormal (that is, $\\mathbf{Q_1^T Q_1}=\\mathbf{I}$) to get:\n",
        "\n",
        " $\\mathbf{Q_1^T A}=\\mathbf{Q_1^T Q_1 R_1}=\\mathbf{R_1}$\n",
        "\n",
        " 2.  We use the to define a new matrix $\\mathbf{A_1}$ which is:\n",
        "\n",
        "   $\\mathbf{A_1}=\\mathbf{R_1 Q_1}$\n",
        "\n",
        "   which, using the above, we can rewrite as:\n",
        "\n",
        "   $\\mathbf{A_1}=\\mathbf{Q_1^T R_1 Q_1}$\n",
        "\n",
        "3.  We iterate this many times.  After $k$ steps we get a sequence of matrices:\n",
        "\n",
        "   $\\mathbf{A_1}=\\mathbf{Q_1^T AQ_1}\\\\\n",
        "   \\mathbf{A_2}=\\mathbf{Q_2^T Q_1^T AQ_1 Q_2}\\\\\n",
        "   \\mathbf{A_3}=\\mathbf{Q_3^T Q_2^T Q_1^T A Q_1 Q_2 Q_3}\\\\\n",
        "   \\vdots \\\\\n",
        "   \\mathbf{A_k}=\\mathbf{\\left(Q_k^T ... Q_1^T\\right) A \\left(Q_1...Q_k\\right)}\n",
        "   $\n",
        "\n",
        "4.  It can be shown (and you can certainly test) that as you repeat this process the matrix $\\mathbf{A_k}$ becomes diagonal.  That is, we'll find that is $k$ becomes large we can approximate $\\mathbf{D} \\approx \\mathbf{A_k}$.  We can define another matrix $\\mathbf{V}$ as:\n",
        "\n",
        "  $\\mathbf{V} = \\mathbf{\\left(Q_1...Q_k\\right)} = \\prod_{i=1}^k \\mathbf{Q_i}$.\n",
        "\n",
        "  Note that since $\\mathbf{V}$ is a product of orthogonal matrices, it is also orthogonal so we can use $\\mathbf{V^T V} = \\mathbf{V V^T} = \\mathbf{I}$.  Putting this in our equation for $\\mathbf{A_k}$ we get:\n",
        "\n",
        "  $ \\mathbf{D}=\\mathbf{V^T A V}$\n",
        "\n",
        "  Which we can multiply both sides by $\\mathbf{V}$ to get:\n",
        "\n",
        "  $ \\mathbf{VD}=\\mathbf{A V}$\n",
        "  \n",
        "  our definition for eigenvectors and eigenvalues!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8yLtt1GXZlJ"
      },
      "source": [
        " **Activity** Lets try implementing this algorithm.  To do this, write code that does the following:\n",
        "\n",
        "1.  Create an $NxN$ matrix for $\\mathbf{V}$ for the eigenvectors, and initially set it equal to the identity matrix $\\mathbf{I} of the same size.\n",
        "\n",
        "2. Calculate the QR decomposition of $\\mathbf{A}=\\mathbf{QR}$\n",
        "\n",
        "3.  Update $\\mathbf{A}$ to the new value $\\mathbf{A}=\\mathbf{RQ}$\n",
        "\n",
        "4.  Update $\\mathbf{V}$ to the new value $\\mathbf{V}=\\mathbf{VQ}$ (that is, multiply $\\mathbf{V}$ on the right by $\\mathbf{Q}$)\n",
        "\n",
        "5.  Repeat steps 2-4 multiple times.  You should stop when the off-diagonal elements are below some small threshold.  Here, you can do this for a fixed number of iterations, or if you have time you can check the off-diagonal elements to see if they are below some small number (such as $10^{-8}$) and perform the above iterations until this criteria is met.\n",
        "\n",
        "Try your code on the matrix $\\mathbf{A}$ that we defined above.  When you are done, check to make sure your eigenvectors are all orthogonal to one another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-aX7nhb6xu4"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import linalg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztiRZUiQarxY"
      },
      "source": [
        "This function is useful for determining the maximum off-diagonal element (there are more efficient ways this could be written, but this is fairly easy to understand)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btve12YKanlC"
      },
      "source": [
        "def max_offdiag(A):\n",
        "  maxval = 0.0\n",
        "  N=A.shape[0]\n",
        "  for i in range(N):\n",
        "    for j in range(N):\n",
        "      if i != j and np.abs(A[i,j]) > maxval :\n",
        "        maxval = np.abs(A[i,j])\n",
        "  return maxval\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il629ICWa28m"
      },
      "source": [
        "First define our matrix.  Then perform iterations of our QR algorithm until the maximum off-diagonal element is below our threshold.  Then print the eigenvectors and eigenvalues.  Note that $\\mathbf{V}$ is an orthonormal matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJe5ZRc6Wfoh",
        "outputId": "9faff7ca-705c-4b49-b146-7a4f5618b6a3"
      },
      "source": [
        "A= np.array([[2,4,6,9],[4,8,3,4],[6,3,2,1],[9,4,1,1]])\n",
        "\n",
        "epsilon = 1e-8\n",
        "\n",
        "V = np.identity(4)\n",
        "\n",
        "maxerror = 1.0\n",
        "\n",
        "while maxerror > epsilon:\n",
        "  Q,R=linalg.qr(A)\n",
        "  A = R@Q\n",
        "  V = V@Q\n",
        "  maxerror = max_offdiag(A)\n",
        "\n",
        "print(\"Eigenvectors:\\n\",V)\n",
        "print(\"Eigenvalues:\\n\")\n",
        "for i in range(4):\n",
        "  print(A[i,i])\n",
        "\n",
        "for i in range(4):\n",
        "  for j in range(i,4):\n",
        "    print(\"The dot product for column\",i,\"and\",j,\"is: %6.4f\"%np.dot(V[:,i],V[:,j]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eigenvectors:\n",
            " [[-0.56868399 -0.69840234  0.42736047  0.07871291]\n",
            " [-0.56477136 -0.04425133 -0.82405938  0.00112746]\n",
            " [-0.36423525  0.34329287  0.23005319 -0.83460064]\n",
            " [-0.47430425  0.62643914  0.29217237  0.5452016 ]]\n",
            "Eigenvalues:\n",
            "\n",
            "17.32175232021623\n",
            "-8.768440625318817\n",
            "3.669861887660925\n",
            "0.7768264174416376\n",
            "The dot product for column 0 and 0 is: 1.0000\n",
            "The dot product for column 0 and 1 is: 0.0000\n",
            "The dot product for column 0 and 2 is: 0.0000\n",
            "The dot product for column 0 and 3 is: -0.0000\n",
            "The dot product for column 1 and 1 is: 1.0000\n",
            "The dot product for column 1 and 2 is: -0.0000\n",
            "The dot product for column 1 and 3 is: -0.0000\n",
            "The dot product for column 2 and 2 is: 1.0000\n",
            "The dot product for column 2 and 3 is: 0.0000\n",
            "The dot product for column 3 and 3 is: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vu4tzLnWfVm"
      },
      "source": [
        "## Computing eigenvalues and eigenvectors with python\n",
        "\n",
        "Similar to dealing with simultaneous linear equations, the problem of solving for eigenvalues and eigenvectors is so ubiquitous that they are built into standard python packages.  In particular, in numpy and scipy we can use the linear algebra's ```linalg.eig``` function:\n",
        "\n",
        "```\n",
        "evalues, evectors = linalg.eig(A)\n",
        "```\n",
        "\n",
        "will compute the eigenvalues (```lambda```) and matrix of eigenvectors (```V```) for the matrix ```A```.\n",
        "\n",
        "**Activity** Try the linalg.eig function for the matrix you computed in the previous activity.  How do the results compare? (Be careful here, you may need to re-initialize your matrix $A$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f38rfBKfMVT9",
        "outputId": "5618b12c-de66-406d-d317-5c4eaf3c3c50"
      },
      "source": [
        "A= np.array([[2,4,6,9],[4,8,3,4],[6,3,2,1],[9,4,1,1]])\n",
        "evalues, evectors = linalg.eig(A)\n",
        "print(\"Eigenvalues = \\n\",evalues)\n",
        "print(\"Eigenvectors = \\n\",evectors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eigenvalues = \n",
            " [17.32175232+0.j -8.76844063+0.j  3.66986189+0.j  0.77682642+0.j]\n",
            "Eigenvectors = \n",
            " [[ 0.56868399  0.69840234 -0.42736047  0.07871291]\n",
            " [ 0.56477136  0.04425133  0.82405938  0.00112746]\n",
            " [ 0.36423525 -0.34329287 -0.23005319 -0.83460064]\n",
            " [ 0.47430425 -0.62643914 -0.29217237  0.5452016 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq4IuPeXN9Mj"
      },
      "source": [
        "**Activity** With large datasets we often want to calculate eigenvectors and eigenvalues.  This can be particularly important for helping us to understand the how are system is changing when we have a lot of noisy data.  Similar to last class, use the ```timeit``` function to determine how big of a matrix you can realistically find the eigenvectors and eigenvalues of.  How does this compare to the maximum practical matrix size you found last class for solving simultaneous linear equations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tHQLBYcMYbE",
        "outputId": "3a98297c-f9f4-49b0-9ca9-f17a9592c9f0"
      },
      "source": [
        "%%timeit -n 10\n",
        "N = 500\n",
        "A=np.random.random([N,N])\n",
        "linalg.eig(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 446 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvQJdkKLPHu5"
      },
      "source": [
        "## Hermitian matrices (if you have time)\n",
        "\n",
        "Oftentimes in physics we'll have matrices that are either symmetric with real numbers or Hermitian (that is, the real parts are symmetric and the complex parts are conjugates of one another for elements $a_{ij}$ and $a_{ji}$).  In fact, the QR algorithm above is only applicable for symmetric matrices.  The general ```linalg.eig``` function uses general routines for calculating eigenvectors and eigenvalues.  But if you have a symmetric matrix you can use more specific (and faster) algorithms.  In particular, the ```linalg.eigh``` function assumes you have a Hermitian matrix.  Repeat the above activity, trying the code below instead.  How much more efficient is this algorithm?  Note there is an additional line of ```A= A+ A.T``` which forces the matrix ```A``` to be symmetric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwEvsOE9O3Sa",
        "outputId": "b877f6c7-2489-41de-ae5d-4fd09fa64f8e"
      },
      "source": [
        "%%timeit -n 10\n",
        "N = 500\n",
        "A=np.random.random([N,N])\n",
        "A = A+A.T\n",
        "linalg.eigh(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 71.3 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}